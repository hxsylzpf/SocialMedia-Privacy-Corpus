{
  "content": "I recently heard some commercial radio DJ's claim that \"nobody uses Facebook any more\". Facebook is the most popular social network on Earth, with more than 1 billion users, so this is really stretching the definition of \"nobody\". Given its direct access to nearly 15% of the human race, it would be fair to say that Facebook wields considerable power, so perhaps it shouldn't be surprising to find it has been running experiments on some users, without their knowledge. The reaction to this has been extensive and varied. Some are OK with it, many aren't. There are people better qualified than me to discuss the ethical/methodological concerns and scientific validity of this study. But one thing that shouldn't be overlooked is, who says this is the only research Facebook is doing? It has published the findings of one experiment, but why stop there? With its influence and resources, there's no telling what it could be up to. Maybe the quirks and irritations many Facebook users complain about are the result of active scientific manipulation? So here are just a few possible studies that we could be unwitting subjects for. Refining passive-aggressive manipulation If you use Facebook at all, you will have come across some emotional or controversial status/post/photo that compels you to share it via the tactic of passive aggressive bullying, usually via a statement akin to \"share this on your wall if you agree. I bet 90% of you won't.\" As distasteful as this crude attempt at manipulation may seem, there is some interesting psychology to be looked into. Firstly, does it work? It should be possible to calculate whether the manipulation is effective or accurate by calculating the number of friends who do share the post, divided by the number of friends the poster has in total, giving us an accurate measurement of those who \"don't\" share it. Compare this with people of similar Facebook properties who share the same post without the manipulation, or the same person sharing similar things at a different time without the manipulation, and you could see how effective it is. The % quoted could also be looked at. In his excellent new book Alex Through the Looking Glass, maths wiz and fellow Guardian blogger Alex Bellos reveals how certain numbers trigger specific psychological reactions in the typical human mind (eg some numbers are more \"pleasant\" than others). This would also have implications for coercing people to share a post of yours. Maybe Facebook is actually behind the constantly varying passive-aggressive posts? It could be monitoring the reactions in order to find out which ones are the most effective. For a company that profits so much from advertising, such data could be invaluable. Developing a digital currency For a profit-driven online organisation, digital currency could have many uses for Facebook. However, current currencies aren't ideal, given their patchy usage and control by central organisations outside of Facebook, among other problems. If only there were some form of currency that was widely recognised, sought after, available in large quantities and controlled exclusively by Facebook. It's possible that Facebook is endeavouring to transform the \"Like\" into an actual currency. Consider that you don't join groups any more, you \"Like\" pages. Facebook has been very reluctant to introduce a \"Dislike\" option. People often put a lot of effort into obtaining \"Likes\" on Facebook, much like someone would perform tasks and labour in return for payment. The psychological framework is there for the \"Like\" to become recognised as inherently valuable. And with those amusing cat pictures and inspirational images racking up millions of \"Likes\" safely stored on Facebook's servers like the gold in Fort Knox, that value could be ensured and maintained. Of course, users can award as many \"Likes\" as they\u2026 like. But these \"Likes\" are dispensed entirely by Facebook, meaning they would also be the mint of a self-contained economy. Some will probably note that this makes no sense economically, but when has economics ever made sense? Preparing workers for a post-apocalyptic society One of the major gripes you will hear about Facebook is the frequency of invites to play games. Arguably the most well-known example of this is Farmville, a game where you basically run a virtual farm and invite others to join you and do the same. If that sounds like spending a lot of time dedicated to growing and cultivating things that aren't actually there, you'd be right. Farmville has no shortage of detractors. Despite its irrelevance and the fact that its popularity has seemingly long since peaked, Farmville has proven weirdly addictive, resulting in people receiving constant invites to take part, annoying many. If something is this annoying and pointless, why would Facebook let it become so widespread? The obvious answer may be \"for profit and to get more users\", but what if it's something darker? Given that Facebook can constantly see what a decent chunk of humanity is up to, it could well be aware of any trends or plans that would lead to civilisational collapse before the rest of us. And if civilisation were to collapse, one thing that would no longer be as relevant would be online social networks. We'd probably have to return to living off the land for survival, with no time or access to online activities. So Facebook would be defunct. Unless, of course, it had done some extensive study which told it who in the general population had the greatest enthusiasm for agricultural work, had no problem with repetitive tasks that seem to achieve nothing, and were keen to recruit others to do the same. Such people would be ideal recruits in a post-technological society, especially if they were to be brought under the control of some powerful but recognisable organisation from before the collapse. And those who complained or objected to being asked to take part would be \"unnecessary\" in this new world order. So yeah, just let that sink in. Population control via censorship One thing that people have often commented on is Facebook's confusing censorship policies (although this seems a problem with social media in general). However, one area where Facebook (and Facebook-owned Instagram) appears oddly draconian is on the displaying of nudity, especially visible female breasts, which is a definite no-no. Many chalk this up to the oppressive, out-dated puritanical views of the Facebook founders, others to the constant body-shaming of women endemic in society. It could easily be any of these things, or similar. Or, it could be an audacious attempt to steer human evolution and limit population growth. Given how much time people spend on Facebook, cutting them off from the naked human form may reduce sexual impulses overall, which could lead to an appreciable reduction in the rate of population increase. Overpopulation is a big threat to the planet, so maybe Facebook is trying to do something good for mankind? And it might even work, as long as none of its users have the ability to access other sites on the net. But of course, there are no other sites. Only Facebook. Facebook is your friend. Trust in Facebook. Dean Burnett is on Facebook, but only for research. And on Twitter, also for research. And rubbish jokes. @garwboy Charles Arthur: Facebook emotion study breached ethical guidelines, researchers say Stuart Dredge: How does Facebook decide what to show in my newsfeed?",
  "title": "Using Facebook for science \u2013 a guide for megalomaniacs | Dean Burnett",
  "lead": "Dean Burnett: The fact that Facebook is conducting experiments on users could be just the tip of the iceberg",
  "tags": [
    "science/psychology",
    "science/science",
    "technology/facebook",
    "technology/research",
    "technology/internet",
    "media/socialnetworking",
    "technology/technology"
  ],
  "core-words": null,
  "id": "science/brain-flapping/2014/jun/30/using-facebook-for-science-a-guide-for-megalomaniacs",
  "class": null,
  "words": null
}