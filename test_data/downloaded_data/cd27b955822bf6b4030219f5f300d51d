{
  "content": "A lawyer and genetic scientist has raised the disturbing possibility of false matches being made in the police national DNA database (NDNAD). He suggests that the DNA database \u2013 which at the end of September 2008 had 4,343,624, samples, including those from hundreds of thousands of innocent people \u2013 is now so large that it is mathematically predicted an innocent person will be matched to a crime they did not commit. This has been recognised for some time but Brian Costello's reasoning is very persuasive and it concerns the continuous comparison of new DNA samples taken during arrest or from volunteers with the DNA taken from nearly half a million crime scenes \"Whenever a new subject sample is loaded on to the NDNAD,\" he writes in the Crimeline briefing for lawyers, \"it is compared with all the existing crime scene samples to cross-check for a match. Correspondingly, whenever a new crime scene sample is loaded onto the NDNAD it is compared to all the subject samples to cross-check for a match. Crime scene samples are also compared to all the other crime scene samples to check if crime scenes are linked.\" Here is the important bit. \"The number of comparisons being made as samples are continually uploaded to the NDNAD is enormous. For example, each time a new crime scene sample is loaded it is automatically compared to the 5m odd subject samples. The next crime scene sample is also compared to the 5m subject samples. Assuming the two crime scene samples are different, then 10m comparisons have been made from the uploading of just two fresh crime scene samples.\" Costello, who worked for five years as a genetic researcher, is now completing his qualification as a barrister in Britain, having qualified as a lawyer in Australia in 2004. He sets out the case mathematically and claims that due to the size of the database and the number of comparisons being made \"full profile chance matches (adventitious matches) are now actually expected to have occurred\". Costello says that it is accepted that under ideal conditions there will be one false match per one trillion checks. He calculates that about 2.5tn comparisons have been made (500,000 [crime scene samples] x 5,000,000 [subject samples] = 2,500,000,000,000) so it is reasonable to expect that at least two errors have occurred. But he adds, \"Unfortunately, a simple mathematical analysis will not give the true picture. Two factors will increase the probability of adventitious matches: firstly, the condition of crime scene samples may lead to incomplete profiles; and secondly, individuals who are related are more likely to share the same profile than unrelated individuals.\" Costello's research continues but what seems clear to me is that a system that is claimed to be foolproof has inbuilt flaws that are beginning to take effect when there are just 4.3m samples on record. What happens if there are 60m samples on the NDNAD? And what about the profiles of innocent people kept by this appalling government despite the European court's ruling? You only have to think of the false positives that have already been perpetrated in the criminal records bureau to realise that this technology is far from perfect even though juries are led to believe that it is. So, you've got nothing to fear if you've done nothing wrong? Rubbish.",
  "title": "The rising odds of DNA false matches | Henry Porter",
  "core-words": null,
  "tags": [
    "politics/dna-database",
    "world/privacy",
    "uk/police",
    "law/law"
  ],
  "lead": "Henry Porter: The size of the national DNA database now makes false matches a mathematical probability",
  "id": "commentisfree/henryporter/2009/may/25/dna-database-false-positive",
  "class": null,
  "words": null
}